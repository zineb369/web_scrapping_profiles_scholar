{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4745cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "\n",
    "# Set the User-Agent header to mimic a browser\n",
    "headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_2) AppleWebKit/601.3.9 (KHTML, like Gecko) Version/9.0.2 Safari/601.3.9'}\n",
    "\n",
    "# List of profile URLs to scrape\n",
    "profile_urls = [\n",
    "    # Add profile URLs as needed\n",
    "]\n",
    "\n",
    "# Lists to store data\n",
    "Statut_Depuis_2018 = []  # List to store status since 2018\n",
    "Statut_global = []      # List to store global status\n",
    "ArticleListe = []       # List to store article information\n",
    "\n",
    "# Function to extract data from the table of statistics\n",
    "def gettableofsat(soup):\n",
    "    table_of_sat = soup.find(id='gsc_rsb_st')\n",
    "    body_of_table = table_of_sat.contents[1]\n",
    "    hs_indeces = body_of_table.contents[1].find_all(\"td\", {'class': 'gsc_rsb_std'})\n",
    "    Citations = body_of_table.contents[0].find_all(\"td\", {'class': 'gsc_rsb_std'})\n",
    "    h_indice_I10 = body_of_table.contents[2].find_all(\"td\", {'class': 'gsc_rsb_std'})\n",
    "\n",
    "    Statut_Depuis_2018.append({\"H indice\": hs_indeces[0].text.strip(), \"Citations\": Citations[0].text.strip(),\n",
    "                               \"H indice_I10\": hs_indeces[0].text.strip()})\n",
    "    Statut_global.append({\"H indice\": hs_indeces[1].text.strip(), \"Citations\": Citations[1].text.strip(),\n",
    "                          \"H indice_I10\": h_indice_I10[1].text.strip()})\n",
    "\n",
    "# Function to get the name of the profile\n",
    "def getNameProfil(soup):\n",
    "    NomProfil = soup.find(id='gsc_prf_in').text.strip()\n",
    "    return NomProfil\n",
    "\n",
    "# Function to get the associated university or institution\n",
    "def getUnevercity(soup):\n",
    "    assc_or_univer = soup.find(\"div\", {'class': 'gsc_prf_il'})\n",
    "    Assc_unevercity = assc_or_univer.get_text(strip=True)\n",
    "    return Assc_unevercity\n",
    "\n",
    "# Function to get the specialty of the profile\n",
    "def spicialty(soup):\n",
    "    spicialty = soup.find(id=\"gsc_prf_int\")\n",
    "    Specialty = spicialty.get_text(strip=True)\n",
    "    return Specialty\n",
    "\n",
    "# Function to extract information about all articles\n",
    "def getArticle(soup):\n",
    "    articles = []\n",
    "    for article in soup.find_all(\"tr\", {'class': 'gsc_a_tr'}):\n",
    "        article_info = {\n",
    "            \"Nom Article\": article.find(\"a\", {'class': 'gsc_a_at'}).text.strip(),\n",
    "            \"description\": article.find(\"div\", {'class': 'gs_gray'}).text.strip(),\n",
    "            \"auteur\": article.find(\"div\", {'class': 'gs_gray'}).find_next(\"div\", {'class': 'gs_gray'}).text.strip(),\n",
    "            \"Annee\": article.find(\"span\", {'class': 'gsc_a_h gsc_a_hc gs_ibl'}).text.strip(),\n",
    "        }\n",
    "        articles.append(article_info)\n",
    "    return articles\n",
    "\n",
    "# Function to scrape profile information\n",
    "def scrape_profile(url):\n",
    "    page = requests.get(url, headers=headers)\n",
    "    src = page.content\n",
    "    soup = BeautifulSoup(src, \"lxml\")\n",
    "\n",
    "    NomProfil = getNameProfil(soup)\n",
    "    Assc_unevercity = getUnevercity(soup)\n",
    "    Specialty = spicialty(soup)\n",
    "    gettableofsat(soup)\n",
    "    ArticleListe = getArticle(soup)\n",
    "\n",
    "    return {\n",
    "        \"Nom et Pr√©nom\": NomProfil,\n",
    "        \"ASS - Unevercity\": Assc_unevercity,\n",
    "        \"Spciality\": Specialty,\n",
    "        \"Status Depuis 2018\": Statut_Depuis_2018,\n",
    "        \"Status Golobal\": Statut_global,\n",
    "        \"Article\": ArticleListe\n",
    "    }\n",
    "\n",
    "# Function to save profile data to a JSON file\n",
    "def save_to_json(profiles, filename='profiles.json'):\n",
    "    with open(filename, 'w', encoding='utf-8') as jsonfile:\n",
    "        json.dump(profiles, jsonfile, ensure_ascii=False, indent=2)\n",
    "\n",
    "# Main function to iterate through profile URLs and scrape data\n",
    "def main():\n",
    "    all_profiles = []\n",
    "\n",
    "    for profile_url in profile_urls:\n",
    "        profile_data = scrape_profile(profile_url)\n",
    "        all_profiles.append(profile_data)\n",
    "\n",
    "    save_to_json(all_profiles)\n",
    "\n",
    "# Check if the script is executed as the main program\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20adc346",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
